[Transformer]
model_arch=gpt2
temperature=0.1

# Runtime parameters only - model dimensions come from weights
max_seq_len=512
vocab_file=vocab.json 
batch_size=1
max_generation_length=20
start_token_id=0
stop_token_id=1