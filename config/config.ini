[Transformer]
num_layers=6
hidden_dim=512
num_heads=8
intermediate_dim=2048
vocab_size=30522
embedding_dim=512
max_seq_len=512
vocab_file=vocab.txt 
batch_size=1
max_generation_length=5
start_token_id=2
stop_token_id=3